{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import cython\n",
    "from mmm import MixtureMarkovChains\n",
    "from scipy import sparse\n",
    "\n",
    "# %load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%cython -a\n",
    "from preprocess import *\n",
    "from utils import *\n",
    "import numpy as np\n",
    "\n",
    "def unique_states(sequences):\n",
    "    states = set()\n",
    "\n",
    "    for seq in sequences:\n",
    "        for state in seq:\n",
    "            if state not in states:\n",
    "                states.add(state)\n",
    "    return list(states)\n",
    "\n",
    "def e_step(alpha, beta, gamma, aij, bijj, i, j, k):\n",
    "    log_alpha = logsafe(alpha).reshape((k, 1))\n",
    "    log_beta = logsafe(beta)\n",
    "    log_gamma = logsafe(gamma).reshape((k, j**2))\n",
    "    \n",
    "    bijj = bijj.reshape((i, j**2))\n",
    "\n",
    "    z = log_alpha.T + np.dot(aij, log_beta.T) + np.dot(bijj, log_gamma.T)\n",
    "\n",
    "    llhood = np.log(np.exp(z).sum(1)).sum()\n",
    "\n",
    "    z = normalize_exp(z, axis=1)\n",
    "    return z, llhood\n",
    "\n",
    "\n",
    "def m_step(z, initial_state, state_transitions, i, j, k):\n",
    "    \"\"\"\n",
    "    calculate the M step\n",
    "    i = number of samples\n",
    "    j = number of categories\n",
    "    K = number of components\n",
    "\n",
    "    :param z_ik: i x K vector of posterior probability\n",
    "    :param initial_frequency: i x j binary vector representing initial states\n",
    "    :param transition_frequency: i x j x j tensor of transition frequencies\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    alpha = z.mean(axis=0)\n",
    "\n",
    "    beta = np.dot(z.T, initial_state)\n",
    "    beta = np.maximum(beta, EPSILON)\n",
    "    beta = normalize(beta, axis=1)\n",
    "\n",
    "    gamma = np.dot(z.T, state_transitions.reshape(i, j**2))\n",
    "    gamma = gamma.reshape((k, j, j))\n",
    "    gamma = np.maximum(gamma, EPSILON)\n",
    "    gamma = normalize(gamma, axis=2)\n",
    "\n",
    "    return alpha, beta, gamma\n",
    "\n",
    "def initialize_params(i, j, k):\n",
    "    alpha = np.random.uniform(0, 1.5, size=(k, ))\n",
    "    alpha /= alpha.sum()\n",
    "\n",
    "    beta = np.random.uniform(0, 1.5, size=(k, j))\n",
    "    beta /= beta.sum(axis=-1, keepdims=True)\n",
    "\n",
    "    gamma = np.random.uniform(0, 1.5, size=(k, j, j))\n",
    "    gamma /= gamma.sum(axis=-1, keepdims=True)\n",
    "    \n",
    "    return alpha, beta, gamma\n",
    "\n",
    "\n",
    "def fit_mmm(seq, n_components=2, epsilon=1e-6, maxiter=1000):\n",
    "    states = unique_states(seq)\n",
    "    \n",
    "    i = len(seq)\n",
    "    j = len(states)\n",
    "    k = n_components\n",
    "    \n",
    "    state_init_count = initial_counts(seq, states)\n",
    "    state_trans_count = transition_counts_stacked(seq, states)\n",
    "    \n",
    "    alpha, beta, gamma = initialize_params(i, j, k)\n",
    "    \n",
    "    llhood_cache = []\n",
    "    \n",
    "    for epoch in range(maxiter):\n",
    "        z, ll = e_step(alpha, beta, gamma, state_init_count, state_trans_count, i, j, k)\n",
    "        alpha, beta, gamma = m_step(z, state_init_count, state_trans_count, i, j, k)\n",
    "        \n",
    "        if epoch >= 1:\n",
    "            if np.abs(ll - llhood_cache[-1]) <= epsilon:\n",
    "                break\n",
    "        \n",
    "        llhood_cache.append(ll)\n",
    "        \n",
    "    return z, (alpha, beta, gamma), ll, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sequences, labels, cat, _, _ = simulate(10000, p=30, maxlen=20, minlen=10)\n",
    "\n",
    "i = len(sequences)\n",
    "j = len(cat)\n",
    "k = 3\n",
    "\n",
    "# %timeit fit_mmm(sequences, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test sparsify versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def initial_counts_sparse(seq, states):\n",
    "    counts = []\n",
    "    row_idx = []\n",
    "    col_idx = []\n",
    "    \n",
    "    j = len(states)\n",
    "\n",
    "    for a in range(len(sequences)):\n",
    "        initial_state = sequences[a][0]\n",
    "        \n",
    "        counts.append(1)\n",
    "        row_idx.append(a)\n",
    "        col_idx.append(initial_state)\n",
    "\n",
    "    initial_counts = sparse.csr_matrix((counts, (row_idx, col_idx)), shape=(i, j))\n",
    "    return initial_counts\n",
    "\n",
    "def transition_counts_sparse(seq, states):\n",
    "    counts = []\n",
    "    row_idx = []\n",
    "    col_idx = []\n",
    "    \n",
    "    j = len(states)\n",
    "\n",
    "    for a in range(len(sequences)):\n",
    "        state_counts = defaultdict(int)\n",
    "        for current, next_ in zip(sequences[a], sequences[a][1:]):\n",
    "            state = current * j + next_\n",
    "\n",
    "            state_counts[state] += 1\n",
    "\n",
    "        counts += list(state_counts.values())\n",
    "        row_idx += [a] * len(state_counts)\n",
    "        col_idx += list(state_counts.keys())\n",
    "\n",
    "    transition_counts = sparse.csr_matrix((counts, (row_idx, col_idx)), shape=(i, j**2))\n",
    "    return transition_counts\n",
    "\n",
    "init_count_sparse = initial_counts_sparse(sequences, cat)\n",
    "init_count_dense = initial_counts(sequences, list(cat))\n",
    "\n",
    "tran_mat_sparse = transition_counts_sparse(sequences, cat)\n",
    "tran_mat_dense = transition_counts_stacked(sequences, list(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.normal(size=(i, k))\n",
    "test = tran_mat_sparse.T.dot(z).T\n",
    "test_dense = np.dot(tran_mat_dense.reshape((-1, j**2)).T, z).T\n",
    "np.all(np.isclose(test, test_dense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 ms ± 1.24 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "269 ms ± 1.56 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit transition_counts_sparse(sequences, cat)\n",
    "%timeit transition_counts_stacked(sequences, list(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "alpha, beta, gamma = initialize_params(i, j, k)\n",
    "\n",
    "z_test, _ = e_step_sparse(alpha, beta, gamma, init_count_sparse, tran_mat_sparse, i, j, k)\n",
    "z_dense, _ = e_step(alpha, beta, gamma, init_count_dense, tran_mat_dense, i, j, k)\n",
    "\n",
    "print(np.all(np.isclose(z_test, z_dense)))\n",
    "\n",
    "alpha_test, beta_test, gamma_test = m_step_sparse(z_test, init_count_sparse, tran_mat_sparse, i, j, k)\n",
    "alpha_dense, beta_dense, gamma_dense = m_step(z_dense, init_count_dense, tran_mat_dense, i, j, k)\n",
    "\n",
    "print(np.all(np.isclose(alpha_test, alpha_dense)))\n",
    "print(np.all(np.isclose(beta_test, beta_dense)))\n",
    "print(np.all(np.isclose(gamma_test, gamma_dense)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def e_step_sparse(alpha, beta, gamma, initial_counts, transition_counts, i, j, k):\n",
    "    log_alpha = logsafe(alpha).reshape((k, 1))\n",
    "    log_beta = logsafe(beta)\n",
    "    log_gamma = logsafe(gamma).reshape((k, j**2))\n",
    "    \n",
    "    z = log_alpha.T + initial_counts.dot(log_beta.T) + transition_counts.dot(log_gamma.T)\n",
    "    \n",
    "    llhood = np.log(np.exp(z).sum(1)).sum()\n",
    "\n",
    "    z = normalize_exp(z, axis=1)\n",
    "    return z, llhood\n",
    "\n",
    "def m_step_sparse(z, initial_counts, transition_counts, i, j, k):\n",
    "    \"\"\"\n",
    "    calculate the M step\n",
    "    i = number of samples\n",
    "    j = number of categories\n",
    "    K = number of components\n",
    "\n",
    "    :param z_ik: i x K vector of posterior probability\n",
    "    :param initial_frequency: i x j binary vector representing initial states\n",
    "    :param transition_frequency: i x j x j tensor of transition frequencies\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    alpha = z.mean(axis=0)\n",
    "    \n",
    "    beta = initial_counts.T.dot(z).T\n",
    "    beta = np.maximum(beta, EPSILON)\n",
    "    beta = normalize(beta, axis=1)\n",
    "\n",
    "    gamma = transition_counts.T.dot(z).T\n",
    "    gamma = gamma.reshape((k, j, j))\n",
    "    gamma = np.maximum(gamma, EPSILON)\n",
    "    gamma = normalize(gamma, axis=2)\n",
    "\n",
    "    return alpha, beta, gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.27 ms ± 21.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "22.9 ms ± 554 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "1.39 ms ± 16.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "11.1 ms ± 164 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import timeit \n",
    "\n",
    "%timeit e_step_sparse(alpha, beta, gamma, init_count_sparse, tran_mat_sparse, i, j, k)\n",
    "%timeit e_step(alpha, beta, gamma, init_count_dense, tran_mat_dense, i, j, k)\n",
    "\n",
    "%timeit m_step_sparse(z_test, init_count_sparse, tran_mat_sparse, i, j, k)\n",
    "%timeit m_step(z_dense, init_count_dense, tran_mat_dense, i, j, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write class to implement MMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovMixture:\n",
    "    def __init__(self, n_components=2, smoothing_factor=1e-6):\n",
    "        self.n_components = n_components\n",
    "        self.smoothing_factor = smoothing_factor\n",
    "        self.transition_matrix = None\n",
    "        self.emission_matrix = None\n",
    "        self.states = None\n",
    "    \n",
    "    def _initialize_params(self, i, j, k):\n",
    "        alpha = np.random.uniform(0, 1.5, size=(k, ))\n",
    "        alpha /= alpha.sum()\n",
    "\n",
    "        beta = np.random.uniform(0, 1.5, size=(k, j))\n",
    "        beta /= beta.sum(axis=-1, keepdims=True)\n",
    "\n",
    "        gamma = np.random.uniform(0, 1.5, size=(k, j, j))\n",
    "        gamma /= gamma.sum(axis=-1, keepdims=True)\n",
    "\n",
    "        return alpha, beta, gamma\n",
    "    \n",
    "    def _unique_states(self, sequences):\n",
    "        unique_states = set()\n",
    "        state_index = dict()\n",
    "        \n",
    "        n_states = 0\n",
    "    \n",
    "        for seq in sequences:\n",
    "            for state in seq:\n",
    "                if state not in unique_states:\n",
    "                    unique_states.add(state)\n",
    "                    state_index[state] = n_states\n",
    "                    n_states += 1\n",
    "        return unique_states, state_index\n",
    "        \n",
    "    def _initialize_sufficient_statistics(self, sequences, state_index):\n",
    "        n_states = len(state_index)\n",
    "        n = len(sequences)\n",
    "        \n",
    "        emission_idx = []\n",
    "        transition_counts = []\n",
    "        row_idx = []\n",
    "        col_idx = []\n",
    "        \n",
    "        for i, seq in enumerate(sequences):\n",
    "            transitions = defaultdict(int)\n",
    "            for j, (current_, next_) in enumerate(zip(seq, seq[1:])):\n",
    "                current_ = state_index[current_]\n",
    "                next_ = state_index[next_]\n",
    "                \n",
    "                if j == 0:\n",
    "                    emission_idx.append(current_)\n",
    "                \n",
    "                index = current_ * n_states + next_\n",
    "                transitions[index] += 1\n",
    "            \n",
    "            transition_counts += list(transitions.values())\n",
    "            row_idx += [i] * len(transitions)\n",
    "            col_idx += list(transitions.keys())\n",
    "            \n",
    "        emission_matrix = sparse.csr_matrix(([1]*n, (range(n), emission_idx)), shape=(n, n_states))\n",
    "        transition_matrix = sparse.csr_matrix((transition_counts, (row_idx, col_idx)), shape=(n, n_states**2))\n",
    "        \n",
    "        return emission_matrix, transition_matrix\n",
    "        \n",
    "    def fit(self, sequences, max_iter=10000, epsilon=1e1-6):\n",
    "        self.states, self.state_index = self._unique_states(sequences)\n",
    "        \n",
    "        emission_matrix, transition_matrix = self._initialize_sufficient_statistics(sequences, self.state_index)\n",
    "        \n",
    "        self.n_states = len(self.states)\n",
    "        \n",
    "        i = len(sequences)\n",
    "        j = self.n_states\n",
    "        k = self.n_components\n",
    "        \n",
    "        alpha, beta, gamma = self._initialize_params(i, j, k)\n",
    "        \n",
    "        llhood_cache = []\n",
    "        \n",
    "        for epoch in range(max_iter):\n",
    "            \n",
    "            \"\"\"\n",
    "            e-step\n",
    "            \"\"\"\n",
    "            log_alpha = logsafe(alpha).reshape((k, 1))\n",
    "            log_beta = logsafe(beta)\n",
    "            log_gamma = logsafe(gamma).reshape((k, j**2))\n",
    "\n",
    "            z = log_alpha.T + emission_matrix.dot(log_beta.T) + transition_matrix.dot(log_gamma.T)\n",
    "\n",
    "            llhood = np.log(np.exp(z).sum(1)).sum()\n",
    "            print(llhood)\n",
    "\n",
    "            z = normalize_exp(z, axis=1)\n",
    "            \n",
    "            if epoch >= 1:\n",
    "                if np.abs(llhood - llhood_cache[-1]) <= epsilon:\n",
    "                    break\n",
    "            \n",
    "            llhood_cache.append(llhood)\n",
    "            \n",
    "            \"\"\"\n",
    "            m-step\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            alpha = z.mean(axis=0)\n",
    "\n",
    "            beta = emission_matrix.T.dot(z).T\n",
    "            beta = np.maximum(beta, EPSILON)\n",
    "            beta = normalize(beta, axis=1)\n",
    "\n",
    "            gamma = transition_matrix.T.dot(z).T\n",
    "            gamma = gamma.reshape((k, j, j))\n",
    "            gamma = np.maximum(gamma, EPSILON)\n",
    "            gamma = normalize(gamma, axis=2)\n",
    "    \n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def predict(self, sequences):\n",
    "        emission_matrix, transition_matrix = self._initialize_sufficient_statistics(sequences, self.state_index)\n",
    "        \n",
    "        i = len(sequences)\n",
    "        j = self.n_states\n",
    "        k = self.n_components\n",
    "        \n",
    "        log_alpha = logsafe(self.alpha).reshape((k, 1))\n",
    "        log_beta = logsafe(self.beta)\n",
    "        log_gamma = logsafe(self.gamma).reshape((k, j**2))\n",
    "\n",
    "        z = log_alpha.T + emission_matrix.dot(log_beta.T) + transition_matrix.dot(log_gamma.T)\n",
    "        z = normalize_exp(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-517733.08852380415\n",
      "-484681.84993309056\n",
      "-483937.9900681542\n",
      "-483233.4606180659\n",
      "-481657.0338737261\n",
      "-478456.6422646474\n",
      "-474927.7823045185\n",
      "-473458.32797743374\n",
      "-473151.28711236827\n",
      "-473087.9188854243\n",
      "-473070.6357116386\n",
      "-473064.9704602212\n",
      "-473062.6653271572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MarkovMixture at 0x1e91ff2a630>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MarkovMixture(3)\n",
    "model.fit(sequences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
